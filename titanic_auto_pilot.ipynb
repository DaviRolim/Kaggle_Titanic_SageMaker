{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "furnished-underwear",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "  Downloading kaggle-1.5.10.tar.gz (59 kB)\n",
      "\u001b[K     |████████████████████████████████| 59 kB 9.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from kaggle) (1.15.0)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from kaggle) (2020.12.5)\n",
      "Requirement already satisfied: python-dateutil in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from kaggle) (2.8.1)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from kaggle) (2.25.1)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from kaggle) (4.42.1)\n",
      "Requirement already satisfied: urllib3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from kaggle) (1.26.2)\n",
      "Collecting python-slugify\n",
      "  Downloading python-slugify-4.0.1.tar.gz (11 kB)\n",
      "Collecting text-unidecode>=1.3\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 738 kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: chardet<5,>=3.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->kaggle) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->kaggle) (2.10)\n",
      "Building wheels for collected packages: kaggle, python-slugify\n",
      "  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.5.10-py3-none-any.whl size=73269 sha256=0db242022c50840e4218c022c1e0c0b518cadcac3c4ef061e4bf27c08de14ad7\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/1c/dd/dd/c493e6f981182c1411e288c553310f76e212bac3afbdac1294\n",
      "  Building wheel for python-slugify (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for python-slugify: filename=python_slugify-4.0.1-py2.py3-none-any.whl size=6767 sha256=aa9c73266cfe4e0192bba24af63aafaed2b6fc68007bd32a956a015700e21a2c\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/72/e6/db/122611605e60148f54ee2abaca98b2bbeafc6e22486a867bad\n",
      "Successfully built kaggle python-slugify\n",
      "Installing collected packages: text-unidecode, python-slugify, kaggle\n",
      "Successfully installed kaggle-1.5.10 python-slugify-4.0.1 text-unidecode-1.3\n",
      "\u001b[33mWARNING: You are using pip version 20.3.3; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "religious-stylus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: kaggle: command not found\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "labeled-nickel",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  titanic.zip\n",
      "  inflating: gender_submission.csv   \n",
      "  inflating: test.csv                \n",
      "  inflating: train.csv               \n"
     ]
    }
   ],
   "source": [
    "!unzip titanic.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "direct-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import time\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "confirmed-conviction",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "# Importing data and merging\n",
    "####################################\n",
    "\n",
    "# Reading dataset\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Adding a column in each dataset before merging\n",
    "train['Type'] = 'train'\n",
    "test['Type'] = 'test'\n",
    "\n",
    "# Merging train and test\n",
    "data = train.append(test)\n",
    "\n",
    "####################################\n",
    "# Missing values and new features\n",
    "####################################\n",
    "\n",
    "# Title\n",
    "data['Title'] = data['Name']\n",
    "\n",
    "# Cleaning name and extracting Title\n",
    "for name_string in data['Name']:\n",
    "    data['Title'] = data['Name'].str.extract('([A-Za-z]+)\\.', expand=True)\n",
    "    \n",
    "# Replacing rare titles \n",
    "mapping = {'Mlle': 'Miss', 'Ms': 'Miss', 'Mme': 'Mrs', 'Major': 'Other', \n",
    "           'Col': 'Other', 'Dr' : 'Other', 'Rev' : 'Other', 'Capt': 'Other', \n",
    "           'Jonkheer': 'Royal', 'Sir': 'Royal', 'Lady': 'Royal', \n",
    "           'Don': 'Royal', 'Countess': 'Royal', 'Dona': 'Royal'}\n",
    "           \n",
    "data.replace({'Title': mapping}, inplace=True)\n",
    "titles = ['Miss', 'Mr', 'Mrs', 'Royal', 'Other', 'Master']\n",
    "\n",
    "# Replacing missing age by median/title \n",
    "for title in titles:\n",
    "    age_to_impute = data.groupby('Title')['Age'].median()[titles.index(title)]\n",
    "    data.loc[(data['Age'].isnull()) & (data['Title'] == title), 'Age'] = age_to_impute\n",
    "    \n",
    "# New feature : Family_size\n",
    "data['Family_Size'] = data['Parch'] + data['SibSp'] + 1\n",
    "data.loc[:,'FsizeD'] = 'Alone'\n",
    "data.loc[(data['Family_Size'] > 1),'FsizeD'] = 'Small'\n",
    "data.loc[(data['Family_Size'] > 4),'FsizeD'] = 'Big'\n",
    "\n",
    "# Replacing missing Fare by median/Pclass \n",
    "fa = data[data[\"Pclass\"] == 3]\n",
    "data['Fare'].fillna(fa['Fare'].median(), inplace = True)\n",
    "\n",
    "#  New feature : Child\n",
    "data.loc[:,'Child'] = 1\n",
    "data.loc[(data['Age'] >= 18),'Child'] =0\n",
    "\n",
    "# New feature : Family Survival (https://www.kaggle.com/konstantinmasich/titanic-0-82-0-83)\n",
    "data['Last_Name'] = data['Name'].apply(lambda x: str.split(x, \",\")[0])\n",
    "DEFAULT_SURVIVAL_VALUE = 0.5\n",
    "\n",
    "data['Family_Survival'] = DEFAULT_SURVIVAL_VALUE\n",
    "for grp, grp_df in data[['Survived','Name', 'Last_Name', 'Fare', 'Ticket', 'PassengerId',\n",
    "                           'SibSp', 'Parch', 'Age', 'Cabin']].groupby(['Last_Name', 'Fare']):\n",
    "                               \n",
    "    if (len(grp_df) != 1):\n",
    "        # A Family group is found.\n",
    "        for ind, row in grp_df.iterrows():\n",
    "            smax = grp_df.drop(ind)['Survived'].max()\n",
    "            smin = grp_df.drop(ind)['Survived'].min()\n",
    "            passID = row['PassengerId']\n",
    "            if (smax == 1.0):\n",
    "                data.loc[data['PassengerId'] == passID, 'Family_Survival'] = 1\n",
    "            elif (smin == 0.0):\n",
    "                data.loc[data['PassengerId'] == passID, 'Family_Survival'] = 0\n",
    "                \n",
    "for _, grp_df in data.groupby('Ticket'):\n",
    "    if (len(grp_df) != 1):\n",
    "        for ind, row in grp_df.iterrows():\n",
    "            if (row['Family_Survival'] == 0) | (row['Family_Survival']== 0.5):\n",
    "                smax = grp_df.drop(ind)['Survived'].max()\n",
    "                smin = grp_df.drop(ind)['Survived'].min()\n",
    "                passID = row['PassengerId']\n",
    "                if (smax == 1.0):\n",
    "                    data.loc[data['PassengerId'] == passID, 'Family_Survival'] = 1\n",
    "                elif (smin == 0.0):\n",
    "                    data.loc[data['PassengerId'] == passID, 'Family_Survival'] = 0\n",
    "                    \n",
    "####################################\n",
    "# Encoding and pre-modeling\n",
    "####################################                  \n",
    "\n",
    "# dropping useless features\n",
    "data = data.drop(columns = ['Age','Cabin','Embarked','Name','Last_Name',\n",
    "                            'Parch', 'SibSp','Ticket', 'Family_Size'])\n",
    "\n",
    "# Encoding features\n",
    "target_col = [\"Survived\"]\n",
    "id_dataset = [\"Type\"]\n",
    "cat_cols   = data.nunique()[data.nunique() < 12].keys().tolist()\n",
    "cat_cols   = [x for x in cat_cols ]\n",
    "# numerical columns\n",
    "num_cols   = [x for x in data.columns if x not in cat_cols + target_col + id_dataset]\n",
    "# Binary columns with 2 values\n",
    "bin_cols   = data.nunique()[data.nunique() == 2].keys().tolist()\n",
    "# Columns more than 2 values\n",
    "multi_cols = [i for i in cat_cols if i not in bin_cols]\n",
    "# Label encoding Binary columns\n",
    "le = LabelEncoder()\n",
    "for i in bin_cols :\n",
    "    data[i] = le.fit_transform(data[i])\n",
    "# Duplicating columns for multi value columns\n",
    "data = pd.get_dummies(data = data,columns = multi_cols )\n",
    "# Scaling Numerical columns\n",
    "std = StandardScaler()\n",
    "scaled = std.fit_transform(data[num_cols])\n",
    "scaled = pd.DataFrame(scaled,columns = num_cols)\n",
    "# dropping original values merging scaled values for numerical columns\n",
    "df_data_og = data.copy()\n",
    "data = data.drop(columns = num_cols,axis = 1)\n",
    "data = data.merge(scaled,left_index = True,right_index = True,how = \"left\")\n",
    "data = data.drop(columns = ['PassengerId'],axis = 1)\n",
    "\n",
    "# Target = 1st column\n",
    "cols = data.columns.tolist()\n",
    "cols.insert(0, cols.pop(cols.index('Survived')))\n",
    "data = data.reindex(columns= cols)\n",
    "\n",
    "# Cutting train and test\n",
    "train = data[data['Type'] == 1].drop(columns = ['Type'])\n",
    "test = data[data['Type'] == 0].drop(columns = ['Type'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "gentle-management",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import boto3\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "session = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()\n",
    "bucket = session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "metropolitan-thumbnail",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((722, 19), (169, 19))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msk = np.random.rand(len(train)) < 0.8\n",
    "df_train = train[msk]\n",
    "df_valid = train[~msk]\n",
    "df_train.shape, df_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "hired-discrimination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data uploaded to: s3://sagemaker-us-east-1-475414269301/sagemaker/titanic/autopilot/train/df_train.csv\n",
      "Test data uploaded to: s3://sagemaker-us-east-1-475414269301/sagemaker/titanic/autopilot/test/df_test.csv\n"
     ]
    }
   ],
   "source": [
    "prefix = 'sagemaker/titanic/autopilot'\n",
    "train_file = 'df_train.csv';\n",
    "#I'll pass the hole training dataset as autopilot doenst need validation dataset\n",
    "train.to_csv(train_file, index=False, header=True)\n",
    "train_data_s3_path = session.upload_data(path=train_file, key_prefix=prefix + \"/train\")\n",
    "print('Train data uploaded to: ' + train_data_s3_path)\n",
    "\n",
    "test_file = 'df_test.csv';\n",
    "df_valid.to_csv(test_file, index=False, header=False)\n",
    "test_data_s3_path = session.upload_data(path=test_file, key_prefix=prefix + \"/test\")\n",
    "print('Test data uploaded to: ' + test_data_s3_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "gross-genealogy",
   "metadata": {},
   "outputs": [],
   "source": [
    "### END OF FEATURE ENGINEERING NOW WE ARE GOING TO TRY DIFFERENT APPROACHES TO \n",
    "# Following the Kaggle Kernel, this is where he start to train models, he uses Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "friendly-metropolitan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import re, sys, math, json, os, sagemaker, urllib.request\n",
    "from sagemaker import get_execution_role                                           \n",
    "from time import gmtime, strftime                 \n",
    "from sagemaker.predictor import csv_serializer   \n",
    "\n",
    "\n",
    "sm = boto3.Session().client(service_name='sagemaker',region_name=region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "registered-hacker",
   "metadata": {},
   "source": [
    "### START: AUTOPILOT FOR THIS FIRST SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "naked-faith",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autopilot config\n",
    "input_data_config = [{\n",
    "      'DataSource': {\n",
    "        'S3DataSource': {\n",
    "          'S3DataType': 'S3Prefix',\n",
    "          'S3Uri': 's3://{}/{}/train'.format(bucket,prefix)\n",
    "        }\n",
    "      },\n",
    "      'TargetAttributeName': 'Survived'\n",
    "    }\n",
    "  ]\n",
    "\n",
    "output_data_config = {\n",
    "    'S3OutputPath': 's3://{}/{}/output'.format(bucket,prefix)\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "funny-quarter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoMLJobName: titanic-06-16-54-20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'AutoMLJobArn': 'arn:aws:sagemaker:us-east-1:475414269301:automl-job/titanic-06-16-54-20',\n",
       " 'ResponseMetadata': {'RequestId': '3c5d42ad-f31c-4686-9c43-23f02b71614d',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '3c5d42ad-f31c-4686-9c43-23f02b71614d',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '90',\n",
       "   'date': 'Sat, 06 Mar 2021 16:54:20 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamp_suffix = strftime('%d-%H-%M-%S', gmtime())\n",
    "\n",
    "auto_ml_job_name = 'titanic-' + timestamp_suffix\n",
    "print('AutoMLJobName: ' + auto_ml_job_name)\n",
    "\n",
    "sm.create_auto_ml_job(AutoMLJobName=auto_ml_job_name,\n",
    "                      InputDataConfig=input_data_config,\n",
    "                      OutputDataConfig=output_data_config,\n",
    "                      AutoMLJobConfig={'CompletionCriteria':\n",
    "                                       {'MaxCandidates': 100}\n",
    "                                      },\n",
    "                      RoleArn=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adjusted-television",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'auto_ml_job_name' (str)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'titanic-06-16-54-20'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Store the AutoMLJobName name for use in subsequent notebooks \n",
    "%store auto_ml_job_name\n",
    "auto_ml_job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "optional-sensitivity",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JobStatus - Secondary Status\n",
      "------------------------------\n",
      "InProgress - AnalyzingData\n",
      "InProgress - AnalyzingData\n",
      "InProgress - AnalyzingData\n",
      "InProgress - AnalyzingData\n",
      "InProgress - AnalyzingData\n",
      "InProgress - AnalyzingData\n",
      "InProgress - AnalyzingData\n",
      "InProgress - AnalyzingData\n",
      "InProgress - AnalyzingData\n",
      "InProgress - AnalyzingData\n",
      "InProgress - AnalyzingData\n",
      "InProgress - AnalyzingData\n",
      "InProgress - AnalyzingData\n",
      "InProgress - AnalyzingData\n",
      "InProgress - AnalyzingData\n",
      "InProgress - AnalyzingData\n",
      "InProgress - AnalyzingData\n",
      "InProgress - FeatureEngineering\n",
      "InProgress - FeatureEngineering\n",
      "InProgress - FeatureEngineering\n",
      "InProgress - FeatureEngineering\n",
      "InProgress - FeatureEngineering\n",
      "InProgress - FeatureEngineering\n",
      "InProgress - FeatureEngineering\n",
      "InProgress - FeatureEngineering\n",
      "InProgress - FeatureEngineering\n",
      "InProgress - FeatureEngineering\n",
      "InProgress - FeatureEngineering\n",
      "InProgress - FeatureEngineering\n",
      "InProgress - FeatureEngineering\n",
      "InProgress - FeatureEngineering\n",
      "InProgress - FeatureEngineering\n",
      "InProgress - FeatureEngineering\n",
      "InProgress - FeatureEngineering\n",
      "InProgress - FeatureEngineering\n",
      "InProgress - FeatureEngineering\n",
      "InProgress - FeatureEngineering\n",
      "InProgress - ModelTuning\n",
      "InProgress - ModelTuning\n",
      "InProgress - ModelTuning\n",
      "InProgress - ModelTuning\n",
      "InProgress - ModelTuning\n",
      "InProgress - ModelTuning\n",
      "InProgress - ModelTuning\n",
      "InProgress - ModelTuning\n",
      "InProgress - ModelTuning\n",
      "InProgress - ModelTuning\n",
      "InProgress - ModelTuning\n",
      "InProgress - ModelTuning\n",
      "InProgress - ModelTuning\n",
      "InProgress - ModelTuning\n",
      "InProgress - ModelTuning\n",
      "InProgress - ModelTuning\n",
      "InProgress - ModelTuning\n",
      "InProgress - ModelTuning\n",
      "InProgress - ModelTuning\n",
      "InProgress - ModelTuning\n",
      "InProgress - ModelTuning\n",
      "InProgress - ModelTuning\n",
      "InProgress - ModelTuning\n",
      "InProgress - ModelTuning\n",
      "InProgress - ModelTuning\n",
      "InProgress - ModelTuning\n",
      "InProgress - ModelTuning\n",
      "InProgress - ModelTuning\n",
      "InProgress - ModelTuning\n",
      "InProgress - ModelTuning\n",
      "InProgress - ModelTuning\n",
      "InProgress - ModelTuning\n",
      "InProgress - ModelTuning\n",
      "InProgress - ModelTuning\n",
      "InProgress - ModelTuning\n",
      "InProgress - ModelTuning\n",
      "InProgress - ModelTuning\n",
      "InProgress - ModelTuning\n",
      "InProgress - ModelTuning\n",
      "InProgress - ModelTuning\n",
      "InProgress - ModelTuning\n",
      "InProgress - ModelTuning\n",
      "InProgress - ModelTuning\n",
      "InProgress - ModelTuning\n",
      "InProgress - ModelTuning\n",
      "InProgress - ModelTuning\n",
      "InProgress - ModelTuning\n",
      "Completed - MaxCandidatesReached\n"
     ]
    }
   ],
   "source": [
    "print ('JobStatus - Secondary Status')\n",
    "print('------------------------------')\n",
    "\n",
    "\n",
    "describe_response = sm.describe_auto_ml_job(AutoMLJobName=auto_ml_job_name)\n",
    "print (describe_response['AutoMLJobStatus'] + \" - \" + describe_response['AutoMLJobSecondaryStatus'])\n",
    "job_run_status = describe_response['AutoMLJobStatus']\n",
    "    \n",
    "while job_run_status not in ('Failed', 'Completed', 'Stopped'):\n",
    "    describe_response = sm.describe_auto_ml_job(AutoMLJobName=auto_ml_job_name)\n",
    "    job_run_status = describe_response['AutoMLJobStatus']\n",
    "    \n",
    "    print (describe_response['AutoMLJobStatus'] + \" - \" + describe_response['AutoMLJobSecondaryStatus'])\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "attended-traveler",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-475414269301/sagemaker/titanic/autopilot/output/titanic-06-16-54-20/sagemaker-automl-candidates/pr-1-d909d0738fc7453f995410df019bbd84cb52a8cfa0e44da4836dd5fa1e/notebooks/SageMakerAutopilotCandidateDefinitionNotebook.ipynb\n",
      "s3://sagemaker-us-east-1-475414269301/sagemaker/titanic/autopilot/output/titanic-06-16-54-20/sagemaker-automl-candidates/pr-1-d909d0738fc7453f995410df019bbd84cb52a8cfa0e44da4836dd5fa1e/notebooks/SageMakerAutopilotDataExplorationNotebook.ipynb\n"
     ]
    }
   ],
   "source": [
    "print(describe_response['AutoMLJobArtifacts']['CandidateDefinitionNotebookLocation'])\n",
    "print(describe_response['AutoMLJobArtifacts']['DataExplorationNotebookLocation'])\n",
    "\n",
    "candidate_nbk = describe_response['AutoMLJobArtifacts']['CandidateDefinitionNotebookLocation']\n",
    "data_explore_nbk = describe_response['AutoMLJobArtifacts']['DataExplorationNotebookLocation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "hybrid-newspaper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-east-1-475414269301 sagemaker/titanic/output/automl-churn-03-15-42-12/sagemaker-automl-candidates/pr-1-c4cf1a7550d04a7ba4a1e624712982dc421136ae7c4345a1a981f305f9/notebooks/SageMakerAutopilotCandidateDefinitionNotebook.ipynb sagemaker/titanic/output/automl-churn-03-15-42-12/sagemaker-automl-candidates/pr-1-c4cf1a7550d04a7ba4a1e624712982dc421136ae7c4345a1a981f305f9/notebooks/SageMakerAutopilotDataExplorationNotebook.ipynb\n"
     ]
    }
   ],
   "source": [
    "def split_s3_path(s3_path):\n",
    "    path_parts=s3_path.replace(\"s3://\",\"\").split(\"/\")\n",
    "    bucket=path_parts.pop(0)\n",
    "    key=\"/\".join(path_parts)\n",
    "    return bucket, key\n",
    "\n",
    "s3_bucket, candidate_nbk_key = split_s3_path(candidate_nbk)\n",
    "_, data_explore_nbk_key = split_s3_path(data_explore_nbk)\n",
    "\n",
    "print(s3_bucket, candidate_nbk_key, data_explore_nbk_key)\n",
    "\n",
    "session.download_data(path='./', bucket=s3_bucket, \n",
    "                                 key_prefix = candidate_nbk_key)\n",
    "\n",
    "session.download_data(path='./', bucket=s3_bucket, \n",
    "                                 key_prefix = data_explore_nbk_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "finished-sunday",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CandidateName': 'tuning-job-1-14df8e6e0b94403b80-083-d8dd10fb', 'FinalAutoMLJobObjectiveMetric': {'MetricName': 'validation:f1', 'Value': 0.8369100093841553}, 'ObjectiveStatus': 'Succeeded', 'CandidateSteps': [{'CandidateStepType': 'AWS::SageMaker::ProcessingJob', 'CandidateStepArn': 'arn:aws:sagemaker:us-east-1:475414269301:processing-job/db-1-d1e5fd82b1fe4d6f97cb244c23571409ab46f4fa6fe64d3481e28991d1', 'CandidateStepName': 'db-1-d1e5fd82b1fe4d6f97cb244c23571409ab46f4fa6fe64d3481e28991d1'}, {'CandidateStepType': 'AWS::SageMaker::TrainingJob', 'CandidateStepArn': 'arn:aws:sagemaker:us-east-1:475414269301:training-job/titanic-06-dpp4-1-88a2c8acde80405c974a62f0205b8920378983434e0a4', 'CandidateStepName': 'titanic-06-dpp4-1-88a2c8acde80405c974a62f0205b8920378983434e0a4'}, {'CandidateStepType': 'AWS::SageMaker::TransformJob', 'CandidateStepArn': 'arn:aws:sagemaker:us-east-1:475414269301:transform-job/titanic-06-dpp4-csv-1-afe3af40db614a63b871a973523d3ab44417e2674', 'CandidateStepName': 'titanic-06-dpp4-csv-1-afe3af40db614a63b871a973523d3ab44417e2674'}, {'CandidateStepType': 'AWS::SageMaker::TrainingJob', 'CandidateStepArn': 'arn:aws:sagemaker:us-east-1:475414269301:training-job/tuning-job-1-14df8e6e0b94403b80-083-d8dd10fb', 'CandidateStepName': 'tuning-job-1-14df8e6e0b94403b80-083-d8dd10fb'}], 'CandidateStatus': 'Completed', 'InferenceContainers': [{'Image': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-sklearn-automl:0.2-1-cpu-py3', 'ModelDataUrl': 's3://sagemaker-us-east-1-475414269301/sagemaker/titanic/autopilot/output/titanic-06-16-54-20/data-processor-models/titanic-06-dpp4-1-88a2c8acde80405c974a62f0205b8920378983434e0a4/output/model.tar.gz', 'Environment': {'AUTOML_TRANSFORM_MODE': 'feature-transform', 'SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT': 'application/x-recordio-protobuf', 'SAGEMAKER_PROGRAM': 'sagemaker_serve', 'SAGEMAKER_SUBMIT_DIRECTORY': '/opt/ml/model/code'}}, {'Image': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.0-1-cpu-py3', 'ModelDataUrl': 's3://sagemaker-us-east-1-475414269301/sagemaker/titanic/autopilot/output/titanic-06-16-54-20/tuning/titanic-06-dpp4-xgb/tuning-job-1-14df8e6e0b94403b80-083-d8dd10fb/output/model.tar.gz', 'Environment': {'MAX_CONTENT_LENGTH': '20971520', 'SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT': 'text/csv', 'SAGEMAKER_INFERENCE_OUTPUT': 'predicted_label', 'SAGEMAKER_INFERENCE_SUPPORTED': 'predicted_label,probability,probabilities'}}, {'Image': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-sklearn-automl:0.2-1-cpu-py3', 'ModelDataUrl': 's3://sagemaker-us-east-1-475414269301/sagemaker/titanic/autopilot/output/titanic-06-16-54-20/data-processor-models/titanic-06-dpp4-1-88a2c8acde80405c974a62f0205b8920378983434e0a4/output/model.tar.gz', 'Environment': {'AUTOML_TRANSFORM_MODE': 'inverse-label-transform', 'SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT': 'text/csv', 'SAGEMAKER_INFERENCE_INPUT': 'predicted_label', 'SAGEMAKER_INFERENCE_OUTPUT': 'predicted_label', 'SAGEMAKER_INFERENCE_SUPPORTED': 'predicted_label,probability,labels,probabilities', 'SAGEMAKER_PROGRAM': 'sagemaker_serve', 'SAGEMAKER_SUBMIT_DIRECTORY': '/opt/ml/model/code'}}], 'CreationTime': datetime.datetime(2021, 3, 6, 17, 30, 2, tzinfo=tzlocal()), 'EndTime': datetime.datetime(2021, 3, 6, 17, 30, 36, tzinfo=tzlocal()), 'LastModifiedTime': datetime.datetime(2021, 3, 6, 17, 36, 11, 964000, tzinfo=tzlocal())}\n",
      "\n",
      "\n",
      "CandidateName: tuning-job-1-14df8e6e0b94403b80-083-d8dd10fb\n",
      "FinalAutoMLJobObjectiveMetricName: validation:f1\n",
      "FinalAutoMLJobObjectiveMetricValue: 0.8369100093841553\n"
     ]
    }
   ],
   "source": [
    "best_candidate = sm.describe_auto_ml_job(AutoMLJobName=auto_ml_job_name)['BestCandidate']\n",
    "best_candidate_name = best_candidate['CandidateName']\n",
    "print(best_candidate)\n",
    "print('\\n')\n",
    "print(\"CandidateName: \" + best_candidate_name)\n",
    "print(\"FinalAutoMLJobObjectiveMetricName: \" + best_candidate['FinalAutoMLJobObjectiveMetric']['MetricName'])\n",
    "print(\"FinalAutoMLJobObjectiveMetricValue: \" + str(best_candidate['FinalAutoMLJobObjectiveMetric']['Value']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "mighty-bench",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sm.describe_auto_ml_job(AutoMLJobName=auto_ml_job_name)\n",
    "#sm.list_auto_ml_jobs()\n",
    "sm_dict =sm.list_candidates_for_auto_ml_job(AutoMLJobName=auto_ml_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "romance-advertiser",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuning-job-1-14df8e6e0b94403b80-097-18e80781 {'MetricName': 'validation:f1', 'Value': 0.7937899827957153}\n",
      "683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.0-1-cpu-py3 \n",
      "\n",
      "tuning-job-1-14df8e6e0b94403b80-098-bc33fa59 {'MetricName': 'validation:f1', 'Value': 0.8098000288009644}\n",
      "683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.0-1-cpu-py3 \n",
      "\n",
      "tuning-job-1-14df8e6e0b94403b80-099-8008e3da {'MetricName': 'validation:f1', 'Value': 0.8162999749183655}\n",
      "683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.0-1-cpu-py3 \n",
      "\n",
      "tuning-job-1-14df8e6e0b94403b80-096-f459ef34 {'MetricName': 'validation:f1', 'Value': 0.8194000124931335}\n",
      "683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.0-1-cpu-py3 \n",
      "\n",
      "tuning-job-1-14df8e6e0b94403b80-094-961beb7b {'MetricName': 'validation:f1', 'Value': 0.8235899806022644}\n",
      "683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.0-1-cpu-py3 \n",
      "\n",
      "tuning-job-1-14df8e6e0b94403b80-093-5d5a7977 {'MetricName': 'validation:binary_f_beta', 'Value': 0.7480915784835815}\n",
      "382416733822.dkr.ecr.us-east-1.amazonaws.com/mxnet-algorithms:inference-cpu \n",
      "\n",
      "tuning-job-1-14df8e6e0b94403b80-100-0d2014b9 {'MetricName': 'validation:f1', 'Value': 0.8098000288009644}\n",
      "683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.0-1-cpu-py3 \n",
      "\n",
      "tuning-job-1-14df8e6e0b94403b80-091-620ed15c {'MetricName': 'validation:f1', 'Value': 0.8314399719238281}\n",
      "683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.0-1-cpu-py3 \n",
      "\n",
      "tuning-job-1-14df8e6e0b94403b80-095-c5566048 {'MetricName': 'validation:f1', 'Value': 0.8205699920654297}\n",
      "683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.0-1-cpu-py3 \n",
      "\n",
      "tuning-job-1-14df8e6e0b94403b80-092-b31089f0 {'MetricName': 'validation:f1', 'Value': 0.8291400074958801}\n",
      "683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.0-1-cpu-py3 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for item in sm_dict['Candidates']:\n",
    "    print(item['CandidateName'], item['FinalAutoMLJobObjectiveMetric'])\n",
    "    print(item['InferenceContainers'][1]['Image'], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "consistent-prison",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = best_candidate_name + timestamp_suffix + \"-model\"\n",
    "model_arn = sm.create_model(Containers=best_candidate['InferenceContainers'],\n",
    "                            ModelName=model_name,\n",
    "                            ExecutionRoleArn=role)\n",
    "\n",
    "epc_name = best_candidate_name + timestamp_suffix + \"-epc\"\n",
    "ep_config = sm.create_endpoint_config(EndpointConfigName = epc_name,\n",
    "                                      ProductionVariants=[{'InstanceType': 'ml.m5.xlarge',\n",
    "                                                           'InitialInstanceCount': 1,\n",
    "                                                           'ModelName': model_name,\n",
    "                                                           'VariantName': 'main'}])\n",
    "\n",
    "ep_name = best_candidate_name + timestamp_suffix + \"-ep\"\n",
    "create_endpoint_response = sm.create_endpoint(EndpointName=ep_name,\n",
    "                                              EndpointConfigName=epc_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "realistic-fishing",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.get_waiter('endpoint_in_service').wait(EndpointName=ep_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "stuck-campus",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import CSVDeserializer\n",
    "predictor = Predictor(\n",
    "    endpoint_name=ep_name,\n",
    "    sagemaker_session=session,\n",
    "    serializer=CSVSerializer(),\n",
    "    deserializer=CSVDeserializer())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "atlantic-print",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tuning-job-1-14df8e6e0b94403b80-083-d8dd10fb06-16-54-20-ep'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "compliant-montreal",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "An error occurred (ValidationError) when calling the InvokeEndpoint operation: Endpoint tuning-job-1-14df8e6e0b94403b80-083-d8dd10fb06-16-54-20-ep of account 475414269301 not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-ecfc77611f96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# X Test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/predictor.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, initial_args, target_model, target_variant)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mrequest_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_request_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_variant\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_runtime_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mrequest_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    356\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    674\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValidationError\u001b[0m: An error occurred (ValidationError) when calling the InvokeEndpoint operation: Endpoint tuning-job-1-14df8e6e0b94403b80-083-d8dd10fb06-16-54-20-ep of account 475414269301 not found."
     ]
    }
   ],
   "source": [
    "# X Test\n",
    "X_test = test.iloc[:, 1:20]\n",
    "predictions = predictor.predict(X_test.values).decode('utf-8')\n",
    "predictions = np.fromstring(predictions, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "delayed-settle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the target column from the test data\n",
    "test_data_inference = X_train_df.drop('Survived', axis=1)\n",
    "#print(test_data_inference.head())\n",
    "\n",
    "# Obtain predictions from SageMaker endpoint\n",
    "prediction = predictor.predict(test_data_inference.to_csv(sep=',', header=False, index=False))\n",
    "\n",
    "# Load prediction in pandas and compare to ground truth\n",
    "prediction_df = pd.DataFrame(prediction)\n",
    "y_train_df = pd.DataFrame(y_train)\n",
    "prediction_df[0] = prediction_df[0].astype(float).apply(lambda x: 1.0 if x > 0.6 else 0.0)\n",
    "accuracy = (y_train_df[0] == prediction_df[0]).sum() / len(test_data_inference)\n",
    "print('Accuracy: {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dental-replica",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test data\n",
    "test_data_inference = X_test_df.drop('Survived', axis=1)\n",
    "prediction = predictor.predict(test_data_inference.to_csv(sep=',', header=False, index=False))\n",
    "prediction_df = pd.DataFrame(prediction)\n",
    "prediction_df[0] = prediction_df[0].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "turkish-tuning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>897</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>898</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>899</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>901</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "891          892         0\n",
       "892          893         1\n",
       "893          894         0\n",
       "894          895         0\n",
       "895          896         1\n",
       "896          897         0\n",
       "897          898         0\n",
       "898          899         0\n",
       "899          900         1\n",
       "900          901         0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('test.csv')\n",
    "submission_df = pd.DataFrame(columns=['PassengerId', 'Survived'])\n",
    "submission_df['PassengerId'] = df_test['PassengerId']\n",
    "submission_df['Survived'] = predictions\n",
    "submission_df['Survived'] = submission_df['Survived'].apply(lambda x: 1 if x > 0.5 else 0)\n",
    "submission_df.to_csv('submissions.csv', header=True, index=False)\n",
    "submission_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "incomplete-venice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/ec2-user/.kaggle/kaggle.json'\n",
      "100%|██████████████████████████████████████| 2.77k/2.77k [00:00<00:00, 6.10kB/s]\n",
      "Successfully submitted to Titanic - Machine Learning from Disaster"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c titanic -f submissions.csv -m \"Submission using autopilot model with 50 candidates only\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "numerous-trinity",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'b7bcd880-4054-4de0-b54b-e21152f3d400',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'b7bcd880-4054-4de0-b54b-e21152f3d400',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '0',\n",
       "   'date': 'Sat, 06 Mar 2021 19:32:23 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deleting the hosted model and deleting the model (Frugality)\n",
    "sm.delete_endpoint(EndpointName=ep_name) \n",
    "sm.delete_endpoint_config(EndpointConfigName=epc_name) \n",
    "sm.delete_model(ModelName=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precise-addition",
   "metadata": {},
   "source": [
    "### END Autopilot submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
